"""
æµ‹è¯•ä¸ªè‚¡èµ„é‡‘æµå‘çˆ¬è™«
"""

import sys
import os
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from eastmoney_scraper import StockCapitalFlowScraper, MarketType

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ä¸ªè‚¡èµ„é‡‘æµå‘çˆ¬è™«")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå…¨å¸‚åœºçˆ¬è™«å®ä¾‹
        scraper = StockCapitalFlowScraper(
            market_type=MarketType.ALL,
            output_dir="output"
        )
        
        print("âœ… çˆ¬è™«å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ‰§è¡Œä¸€æ¬¡çˆ¬å–ï¼Œåªè·å–1é¡µæ•°æ®è¿›è¡Œæµ‹è¯•
        print("ğŸ“¡ å¼€å§‹çˆ¬å–æ•°æ®...")
        df, filepath = scraper.run_once(max_pages=1, save_format='csv')
        
        if not df.empty:
            print(f"âœ… æˆåŠŸçˆ¬å– {len(df)} æ¡æ•°æ®")
            print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
            
            # æ˜¾ç¤ºæ•°æ®åˆ—ä¿¡æ¯
            print(f"\nğŸ“Š æ•°æ®åˆ—ä¿¡æ¯:")
            for col in df.columns:
                print(f"   - {col}")
            
            # æ˜¾ç¤ºå‰5æ¡æ•°æ®
            print(f"\nğŸ“ˆ å‰5æ¡æ•°æ®é¢„è§ˆ:")
            print(df.head().to_string())
            
            # æµ‹è¯•åˆ†æåŠŸèƒ½
            print(f"\nğŸ” å¸‚åœºæ¦‚å†µåˆ†æ:")
            summary = scraper.analyze_market_summary(df)
            for key, value in summary.items():
                print(f"   {key}: {value}")
                
            # æµ‹è¯•ä¸»åŠ›å‡€æµå…¥TOP5
            top_inflow = scraper.get_top_inflow_stocks(df, 5)
            if not top_inflow.empty:
                print(f"\nğŸ”¥ ä¸»åŠ›å‡€æµå…¥TOP5:")
                for _, row in top_inflow.iterrows():
                    print(f"   {row['è‚¡ç¥¨åç§°']}({row['è‚¡ç¥¨ä»£ç ']}): {row['ä¸»åŠ›å‡€æµå…¥']:.2f}ä¸‡å…ƒ")
            
            print(f"\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
            
        else:
            print("âŒ æœªè·å–åˆ°æ•°æ®")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_different_markets():
    """æµ‹è¯•ä¸åŒå¸‚åœºç±»å‹"""
    print(f"\nğŸ§ª æµ‹è¯•ä¸åŒå¸‚åœºç±»å‹")
    print("=" * 60)
    
    markets = [
        (MarketType.GEM, "åˆ›ä¸šæ¿"),
        (MarketType.STAR, "ç§‘åˆ›æ¿"),
        (MarketType.MAIN_BOARD, "ä¸»æ¿")
    ]
    
    for market_type, market_name in markets:
        try:
            print(f"\nğŸ“¡ æµ‹è¯• {market_name} æ•°æ®çˆ¬å–...")
            scraper = StockCapitalFlowScraper(
                market_type=market_type,
                output_dir="output"
            )
            
            df, filepath = scraper.run_once(max_pages=1, save_format='json')
            
            if not df.empty:
                print(f"âœ… {market_name}: æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
                summary = scraper.analyze_market_summary(df)
                print(f"   ä¸Šæ¶¨è‚¡ç¥¨: {summary.get('ä¸Šæ¶¨è‚¡ç¥¨æ•°', 0)} / {summary.get('æ€»è‚¡ç¥¨æ•°', 0)}")
                print(f"   å‡€æµå…¥æ€»é¢: {summary.get('å¸‚åœºä¸»åŠ›å‡€æµå…¥æ€»é¢(ä¸‡å…ƒ)', 0):.2f} ä¸‡å…ƒ")
            else:
                print(f"âš ï¸ {market_name}: æœªè·å–åˆ°æ•°æ®")
                
        except Exception as e:
            print(f"âŒ {market_name} æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    print(f"ğŸš€ å¼€å§‹æµ‹è¯• - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    test_basic_functionality()
    test_different_markets()
    
    print(f"\nğŸ æµ‹è¯•å®Œæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ’¡ æŸ¥çœ‹ç”Ÿæˆçš„outputç›®å½•ä¸­çš„æ•°æ®æ–‡ä»¶")